{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  datetime import datetime, timedelta\n",
    "import gc\n",
    "import numpy as np, pandas as pd\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "> This notebook aims to push the public LB under 0.50. Certainly, the competition is not yet at its peak and there clearly remains room for improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Credits and comments on changes\n",
    "\n",
    "This notebook is based on [m5-first-public-notebook-under-0-50](https://www.kaggle.com/kneroma/m5-first-public-notebook-under-0-50) v.6 by @kkiller \n",
    "\n",
    "Presently it's sole purpose is to test accelerated prediction stage (vs original notebook) where I generate lag features only for the days that need sales forecasts. Everything else is unchanged vs the original _kkiller's_ notebook (as in version 6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAL_DTYPES={\"event_name_1\": \"category\", \"event_name_2\": \"category\", \"event_type_1\": \"category\", \n",
    "         \"event_type_2\": \"category\", \"weekday\": \"category\", 'wm_yr_wk': 'int16', \"wday\": \"int16\",\n",
    "        \"month\": \"int16\", \"year\": \"int16\", \"snap_CA\": \"float32\", 'snap_TX': 'float32', 'snap_WI': 'float32' }\n",
    "PRICE_DTYPES = {\"store_id\": \"category\", \"item_id\": \"category\", \"wm_yr_wk\": \"int16\",\"sell_price\":\"float32\" }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2016, 4, 25, 0, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = 28 \n",
    "max_lags = 57\n",
    "tr_last = 1913\n",
    "fday = datetime(2016,4, 25) \n",
    "fday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dt(is_train = True, nrows = None, first_day = 1200):\n",
    "    prices = pd.read_csv(\"../input/m5-forecasting-accuracy/sell_prices.csv\", dtype = PRICE_DTYPES)\n",
    "    for col, col_dtype in PRICE_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            prices[col] = prices[col].cat.codes.astype(\"int16\")\n",
    "            prices[col] -= prices[col].min()\n",
    "            \n",
    "    cal = pd.read_csv(\"../input/m5-forecasting-accuracy/calendar.csv\", dtype = CAL_DTYPES)\n",
    "    cal[\"date\"] = pd.to_datetime(cal[\"date\"])\n",
    "    for col, col_dtype in CAL_DTYPES.items():\n",
    "        if col_dtype == \"category\":\n",
    "            cal[col] = cal[col].cat.codes.astype(\"int16\")\n",
    "            cal[col] -= cal[col].min()\n",
    "    \n",
    "    start_day = max(1 if is_train  else tr_last-max_lags, first_day)\n",
    "    numcols = [f\"d_{day}\" for day in range(start_day,tr_last+1)]\n",
    "    catcols = ['id', 'item_id', 'dept_id','store_id', 'cat_id', 'state_id']\n",
    "    dtype = {numcol:\"float32\" for numcol in numcols} \n",
    "    dtype.update({col: \"category\" for col in catcols if col != \"id\"})\n",
    "    dt = pd.read_csv(\"../input/m5-forecasting-accuracy/sales_train_validation.csv\", \n",
    "                     nrows = nrows, usecols = catcols + numcols, dtype = dtype)\n",
    "    \n",
    "    for col in catcols:\n",
    "        if col != \"id\":\n",
    "            dt[col] = dt[col].cat.codes.astype(\"int16\")\n",
    "            dt[col] -= dt[col].min()\n",
    "    \n",
    "    if not is_train:\n",
    "        for day in range(tr_last+1, tr_last+ 28 +1):\n",
    "            dt[f\"d_{day}\"] = np.nan\n",
    "    \n",
    "    dt = pd.melt(dt,\n",
    "                  id_vars = catcols,\n",
    "                  value_vars = [col for col in dt.columns if col.startswith(\"d_\")],\n",
    "                  var_name = \"d\",\n",
    "                  value_name = \"sales\")\n",
    "    \n",
    "    dt = dt.merge(cal, on= \"d\", copy = False)\n",
    "    dt = dt.merge(prices, on = [\"store_id\", \"item_id\", \"wm_yr_wk\"], copy = False)\n",
    "    \n",
    "    return dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fea(dt):\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags ]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt[lag_col] = dt[[\"id\",\"sales\"]].groupby(\"id\")[\"sales\"].shift(lag)\n",
    "\n",
    "    wins = [7, 28]\n",
    "    for win in wins :\n",
    "        for lag,lag_col in zip(lags, lag_cols):\n",
    "            dt[f\"rmean_{lag}_{win}\"] = dt[[\"id\", lag_col]].groupby(\"id\")[lag_col].transform(lambda x : x.rolling(win).mean())\n",
    "\n",
    "    \n",
    "    \n",
    "    date_features = {\n",
    "        \n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "#         \"ime\": \"is_month_end\",\n",
    "#         \"ims\": \"is_month_start\",\n",
    "    }\n",
    "    \n",
    "#     dt.drop([\"d\", \"wm_yr_wk\", \"weekday\"], axis=1, inplace = True)\n",
    "    \n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIRST_DAY = 350 # If you want to load all the data set it to '1' -->  Great  memory overflow  risk !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 12.4 s, total: 47.9 s\n",
      "Wall time: 48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40718219, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = create_dt(is_train=True, first_day= FIRST_DAY)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  store_id  cat_id  \\\n",
       "0  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n",
       "1  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n",
       "2  HOBBIES_1_005_CA_1_validation        4        0         0       0   \n",
       "3  HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "4  HOBBIES_1_009_CA_1_validation        8        0         0       0   \n",
       "\n",
       "   state_id      d  sales       date  wm_yr_wk  weekday  wday  month  year  \\\n",
       "0         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "1         0  d_350    2.0 2012-01-13     11150        0     7      1  2012   \n",
       "2         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "3         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "4         0  d_350    2.0 2012-01-13     11150        0     7      1  2012   \n",
       "\n",
       "   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n",
       "0             0             0             0             0      0.0      1.0   \n",
       "1             0             0             0             0      0.0      1.0   \n",
       "2             0             0             0             0      0.0      1.0   \n",
       "3             0             0             0             0      0.0      1.0   \n",
       "4             0             0             0             0      0.0      1.0   \n",
       "\n",
       "   snap_WI  sell_price  \n",
       "0      0.0        3.97  \n",
       "1      0.0        4.34  \n",
       "2      0.0        2.48  \n",
       "3      0.0        0.50  \n",
       "4      0.0        1.77  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40718219 entries, 0 to 40718218\n",
      "Data columns (total 22 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       int16         \n",
      " 11  wday          int16         \n",
      " 12  month         int16         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int16         \n",
      " 15  event_type_1  int16         \n",
      " 16  event_name_2  int16         \n",
      " 17  event_type_2  int16         \n",
      " 18  snap_CA       float32       \n",
      " 19  snap_TX       float32       \n",
      " 20  snap_WI       float32       \n",
      " 21  sell_price    float32       \n",
      "dtypes: datetime64[ns](1), float32(5), int16(14), object(2)\n",
      "memory usage: 3.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 21s, sys: 15.9 s, total: 3min 37s\n",
      "Wall time: 3min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40718219, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "create_fea(df)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 40718219 entries, 0 to 40718218\n",
      "Data columns (total 31 columns):\n",
      " #   Column        Dtype         \n",
      "---  ------        -----         \n",
      " 0   id            object        \n",
      " 1   item_id       int16         \n",
      " 2   dept_id       int16         \n",
      " 3   store_id      int16         \n",
      " 4   cat_id        int16         \n",
      " 5   state_id      int16         \n",
      " 6   d             object        \n",
      " 7   sales         float32       \n",
      " 8   date          datetime64[ns]\n",
      " 9   wm_yr_wk      int16         \n",
      " 10  weekday       int16         \n",
      " 11  wday          int16         \n",
      " 12  month         int16         \n",
      " 13  year          int16         \n",
      " 14  event_name_1  int16         \n",
      " 15  event_type_1  int16         \n",
      " 16  event_name_2  int16         \n",
      " 17  event_type_2  int16         \n",
      " 18  snap_CA       float32       \n",
      " 19  snap_TX       float32       \n",
      " 20  snap_WI       float32       \n",
      " 21  sell_price    float32       \n",
      " 22  lag_7         float32       \n",
      " 23  lag_28        float32       \n",
      " 24  rmean_7_7     float32       \n",
      " 25  rmean_28_7    float32       \n",
      " 26  rmean_7_28    float32       \n",
      " 27  rmean_28_28   float32       \n",
      " 28  week          int16         \n",
      " 29  quarter       int16         \n",
      " 30  mday          int16         \n",
      "dtypes: datetime64[ns](1), float32(11), int16(17), object(2)\n",
      "memory usage: 4.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>lag_7</th>\n",
       "      <th>lag_28</th>\n",
       "      <th>rmean_7_7</th>\n",
       "      <th>rmean_28_7</th>\n",
       "      <th>rmean_7_28</th>\n",
       "      <th>rmean_28_28</th>\n",
       "      <th>week</th>\n",
       "      <th>quarter</th>\n",
       "      <th>mday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_008_CA_1_validation</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_009_CA_1_validation</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>d_350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2012-01-13</td>\n",
       "      <td>11150</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              id  item_id  dept_id  store_id  cat_id  \\\n",
       "0  HOBBIES_1_002_CA_1_validation        1        0         0       0   \n",
       "1  HOBBIES_1_004_CA_1_validation        3        0         0       0   \n",
       "2  HOBBIES_1_005_CA_1_validation        4        0         0       0   \n",
       "3  HOBBIES_1_008_CA_1_validation        7        0         0       0   \n",
       "4  HOBBIES_1_009_CA_1_validation        8        0         0       0   \n",
       "\n",
       "   state_id      d  sales       date  wm_yr_wk  weekday  wday  month  year  \\\n",
       "0         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "1         0  d_350    2.0 2012-01-13     11150        0     7      1  2012   \n",
       "2         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "3         0  d_350    0.0 2012-01-13     11150        0     7      1  2012   \n",
       "4         0  d_350    2.0 2012-01-13     11150        0     7      1  2012   \n",
       "\n",
       "   event_name_1  event_type_1  event_name_2  event_type_2  snap_CA  snap_TX  \\\n",
       "0             0             0             0             0      0.0      1.0   \n",
       "1             0             0             0             0      0.0      1.0   \n",
       "2             0             0             0             0      0.0      1.0   \n",
       "3             0             0             0             0      0.0      1.0   \n",
       "4             0             0             0             0      0.0      1.0   \n",
       "\n",
       "   snap_WI  sell_price  lag_7  lag_28  rmean_7_7  rmean_28_7  rmean_7_28  \\\n",
       "0      0.0        3.97    NaN     NaN        NaN         NaN         NaN   \n",
       "1      0.0        4.34    NaN     NaN        NaN         NaN         NaN   \n",
       "2      0.0        2.48    NaN     NaN        NaN         NaN         NaN   \n",
       "3      0.0        0.50    NaN     NaN        NaN         NaN         NaN   \n",
       "4      0.0        1.77    NaN     NaN        NaN         NaN         NaN   \n",
       "\n",
       "   rmean_28_28  week  quarter  mday  \n",
       "0          NaN     2        1    13  \n",
       "1          NaN     2        1    13  \n",
       "2          NaN     2        1    13  \n",
       "3          NaN     2        1    13  \n",
       "4          NaN     2        1    13  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39041269, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_feats = ['item_id', 'dept_id','store_id', 'cat_id', 'state_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"]\n",
    "useless_cols = [\"id\", \"date\", \"sales\",\"d\", \"wm_yr_wk\", \"weekday\"]\n",
    "train_cols = df.columns[~df.columns.isin(useless_cols)]\n",
    "X_train = df[train_cols]\n",
    "y_train = df[\"sales\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.31 s, sys: 932 ms, total: 9.24 s\n",
      "Wall time: 9.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "np.random.seed(777)\n",
    "\n",
    "fake_valid_inds = np.random.choice(X_train.index.values, 2_000_000, replace = False)\n",
    "train_inds = np.setdiff1d(X_train.index.values, fake_valid_inds)\n",
    "X_train=X_train.loc[fake_valid_inds]\n",
    "y_train = y_train.loc[fake_valid_inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df, X_train, y_train, fake_valid_inds,train_inds ; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#ML Algoirthm\n",
    "from sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.svm import SVR\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=12, random_state=42, shuffle=True)\n",
    "\n",
    "# Define error metrics\n",
    "def cv_rmse(model, X=X_train):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))\n",
    "\n",
    "# Support Vector Regressor\n",
    "#svr = make_pipeline(RobustScaler(), SVR(C= 5, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=100,\n",
    "                                learning_rate=0.075)\n",
    "\n",
    "rf=RandomForestRegressor(n_estimators=10)\n",
    "\n",
    "lightgbm1 = LGBMRegressor(objective='poisson', \n",
    "                       metric ='rmse',\n",
    "                       learning_rate = 0.075,\n",
    "                       sub_row = 0.75,\n",
    "                       bagging_freq = 1,\n",
    "                       lambda_l2 = 0.1,\n",
    "                       verbosity= 1,\n",
    "                       n_estimators = 200,\n",
    "                       num_leaves= 128,\n",
    "                       min_data_in_leaf= 100)\n",
    "lightgbm2 = LGBMRegressor(objective='tweedie', \n",
    "                       metric ='rmse',\n",
    "                       learning_rate = 0.075,\n",
    "                       sub_row = 0.75,\n",
    "                       bagging_freq = 1,\n",
    "                       lambda_l2 = 0.1,\n",
    "                       verbosity= 1,\n",
    "                       n_estimators = 200,\n",
    "                       num_leaves= 128,\n",
    "                       min_data_in_leaf= 100)\n",
    "\n",
    "xgboost = XGBRegressor(objective='count:poisson',\n",
    "                       learning_rate=0.075,\n",
    "                       n_estimators=100,\n",
    "                       min_child_weight=50)\n",
    "\n",
    "stackReg = StackingCVRegressor(regressors=(lightgbm1,lightgbm2),\n",
    "                                meta_regressor=(xgboost),\n",
    "                                use_features_in_secondary=True, \n",
    "                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm1: 2.5093\n"
     ]
    }
   ],
   "source": [
    "model_score = {}\n",
    "\n",
    "score = cv_rmse(lightgbm1)\n",
    "lgb_model1_full_data = lightgbm1.fit(X_train, y_train)\n",
    "print(\"lightgbm1: {:.4f}\".format(score.mean()))\n",
    "model_score['lgb1'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm2: 2.4855\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(lightgbm2)\n",
    "lgb_model2_full_data = lightgbm2.fit(X_train, y_train)\n",
    "print(\"lightgbm2: {:.4f}\".format(score.mean()))\n",
    "model_score['lgb2'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost: 2.6406\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(xgboost)\n",
    "xgboost_full_data = xgboost.fit(X_train, y_train)\n",
    "print(\"xgboost: {:.4f}\".format(score.mean()))\n",
    "model_score['xgb'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge: 2.5529\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(ridge)\n",
    "ridge_full_data = ridge.fit(X_train, y_train)\n",
    "print(\"ridge: {:.4f}\".format(score.mean()))\n",
    "model_score['ridge'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = cv_rmse(svr)\n",
    "# svr_full_data = svr.fit(X_train, y_train)\n",
    "# print(\"svr: {:.4f}\".format(score.mean()))\n",
    "# model_score['svr'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbr: 2.5572\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(gbr)\n",
    "gbr_full_data = gbr.fit(X_train, y_train)\n",
    "print(\"gbr: {:.4f}\".format(score.mean()))\n",
    "model_score['gbr'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf: 2.6767\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(rf)\n",
    "rf_full_data = rf.fit(X_train, y_train)\n",
    "print(\"rf: {:.4f}\".format(score.mean()))\n",
    "model_score['rf'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackReg: 2.6031\n"
     ]
    }
   ],
   "source": [
    "score = cv_rmse(stackReg)\n",
    "stackReg_full_data = stackReg.fit(X_train, y_train)\n",
    "print(\"stackReg: {:.4f}\".format(score.mean()))\n",
    "model_score['stackReg'] = score.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blended_predictions(X_train,weight):\n",
    "    return ((weight[0] * ridge_full_data.predict(X_train)) + \\\n",
    "            (weight[1] * rf_full_data.predict(X_train)) + \\\n",
    "            (weight[2] * gbr_full_data.predict(X_train)) + \\\n",
    "            (weight[3] * xgboost_full_data.predict(X_train)) + \\\n",
    "            (weight[4] * lgb_model1_full_data.predict(X_train)) + \\\n",
    "            (weight[5] * stackReg_full_data.predict(np.array(X_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blended score: 2.0983\n"
     ]
    }
   ],
   "source": [
    "# Blended model predictions\n",
    "blended_score = rmsle(y_train, blended_predictions(X_train,[0.15,0.2,0.18,0.1,0.27,0.1]))\n",
    "print(\"blended score: {:.4f}\".format(blended_score))\n",
    "model_score['blended_model'] =  blended_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgb1': 2.5093082169079213,\n",
       " 'lgb2': 2.4855174805110236,\n",
       " 'xgb': 2.6405596527978523,\n",
       " 'ridge': 2.5529279230920676,\n",
       " 'gbr': 2.557158736995572,\n",
       " 'rf': 2.6766574285787126,\n",
       " 'stackReg': 2.6031457178735606,\n",
       " 'blended_model': 2.0983475471618056}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_model = stacked_ensemble(X_train,y_train)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  %%time\n",
    "# blend= blended_predictions(X_train,[0.15,0.2,0.1,0.18,0.1,0.27])\n",
    "                   "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prediction stage\n",
    "(updated vs original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lag_features_for_test(dt, day):\n",
    "    # create lag feaures just for single day (faster)\n",
    "    lags = [7, 28]\n",
    "    lag_cols = [f\"lag_{lag}\" for lag in lags]\n",
    "    for lag, lag_col in zip(lags, lag_cols):\n",
    "        dt.loc[dt.date == day, lag_col] = \\\n",
    "            dt.loc[dt.date ==day-timedelta(days=lag), 'sales'].values  # !!! main\n",
    "\n",
    "    windows = [7, 28]\n",
    "    for window in windows:\n",
    "        for lag in lags:\n",
    "            df_window = dt[(dt.date <= day-timedelta(days=lag)) & (dt.date > day-timedelta(days=lag+window))]\n",
    "            df_window_grouped = df_window.groupby(\"id\").agg({'sales':'mean'}).reindex(dt.loc[dt.date==day,'id'])\n",
    "            dt.loc[dt.date == day,f\"rmean_{lag}_{window}\"] = \\\n",
    "                df_window_grouped.sales.values     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_features_for_test(dt):\n",
    "    # copy of the code from `create_dt()` above\n",
    "    date_features = {\n",
    "        \"wday\": \"weekday\",\n",
    "        \"week\": \"weekofyear\",\n",
    "        \"month\": \"month\",\n",
    "        \"quarter\": \"quarter\",\n",
    "        \"year\": \"year\",\n",
    "        \"mday\": \"day\",\n",
    "    }\n",
    "\n",
    "    for date_feat_name, date_feat_func in date_features.items():\n",
    "        if date_feat_name in dt.columns:\n",
    "            dt[date_feat_name] = dt[date_feat_name].astype(\"int16\")\n",
    "        else:\n",
    "            dt[date_feat_name] = getattr(\n",
    "                dt[\"date\"].dt, date_feat_func).astype(\"int16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2016-04-25\n",
      "1 2016-04-26\n",
      "2 2016-04-27\n",
      "3 2016-04-28\n",
      "4 2016-04-29\n",
      "5 2016-04-30\n",
      "6 2016-05-01\n",
      "7 2016-05-02\n",
      "8 2016-05-03\n",
      "9 2016-05-04\n",
      "10 2016-05-05\n",
      "11 2016-05-06\n",
      "12 2016-05-07\n",
      "13 2016-05-08\n",
      "14 2016-05-09\n",
      "15 2016-05-10\n",
      "16 2016-05-11\n",
      "17 2016-05-12\n",
      "18 2016-05-13\n",
      "19 2016-05-14\n",
      "20 2016-05-15\n",
      "21 2016-05-16\n",
      "22 2016-05-17\n",
      "23 2016-05-18\n",
      "24 2016-05-19\n",
      "25 2016-05-20\n",
      "26 2016-05-21\n",
      "27 2016-05-22\n",
      "0 1.028 0.3333333333333333\n",
      "0 2016-04-25\n",
      "1 2016-04-26\n",
      "2 2016-04-27\n",
      "3 2016-04-28\n",
      "4 2016-04-29\n",
      "5 2016-04-30\n",
      "6 2016-05-01\n",
      "7 2016-05-02\n",
      "8 2016-05-03\n",
      "9 2016-05-04\n",
      "10 2016-05-05\n",
      "11 2016-05-06\n",
      "12 2016-05-07\n",
      "13 2016-05-08\n",
      "14 2016-05-09\n",
      "15 2016-05-10\n",
      "16 2016-05-11\n",
      "17 2016-05-12\n",
      "18 2016-05-13\n",
      "19 2016-05-14\n",
      "20 2016-05-15\n",
      "21 2016-05-16\n",
      "22 2016-05-17\n",
      "23 2016-05-18\n",
      "24 2016-05-19\n",
      "25 2016-05-20\n",
      "26 2016-05-21\n",
      "27 2016-05-22\n",
      "1 1.023 0.3333333333333333\n",
      "0 2016-04-25\n",
      "1 2016-04-26\n",
      "2 2016-04-27\n",
      "3 2016-04-28\n",
      "4 2016-04-29\n",
      "5 2016-04-30\n",
      "6 2016-05-01\n",
      "7 2016-05-02\n",
      "8 2016-05-03\n",
      "9 2016-05-04\n",
      "10 2016-05-05\n",
      "11 2016-05-06\n",
      "12 2016-05-07\n",
      "13 2016-05-08\n",
      "14 2016-05-09\n",
      "15 2016-05-10\n",
      "16 2016-05-11\n",
      "17 2016-05-12\n",
      "18 2016-05-13\n",
      "19 2016-05-14\n",
      "20 2016-05-15\n",
      "21 2016-05-16\n",
      "22 2016-05-17\n",
      "23 2016-05-18\n",
      "24 2016-05-19\n",
      "25 2016-05-20\n",
      "26 2016-05-21\n",
      "27 2016-05-22\n",
      "2 1.018 0.3333333333333333\n",
      "CPU times: user 7min 4s, sys: 22.6 s, total: 7min 27s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "alphas = [1.028, 1.023, 1.018]\n",
    "weights = [1/len(alphas)]*len(alphas)  # equal weights\n",
    "\n",
    "te0 = create_dt(False)  # create master copy of `te`\n",
    "create_date_features_for_test (te0)\n",
    "\n",
    "for icount, (alpha, weight) in enumerate(zip(alphas, weights)):\n",
    "    te = te0.copy()  # just copy\n",
    "#     te1 = te0.copy()\n",
    "    cols = [f\"F{i}\" for i in range(1, 29)]\n",
    "\n",
    "    for tdelta in range(0, 28):\n",
    "        day = fday + timedelta(days=tdelta)\n",
    "        print(tdelta, day.date())\n",
    "        tst = te[(te.date >= day - timedelta(days=max_lags))\n",
    "                 & (te.date <= day)].copy()\n",
    "#         tst1 = te1[(te1.date >= day - timedelta(days=max_lags))\n",
    "#                  & (te1.date <= day)].copy()\n",
    "#         create_fea(tst)  # correct, but takes much time\n",
    "        create_lag_features_for_test(tst, day)  # faster  \n",
    "        tst = tst.loc[tst.date == day, train_cols]\n",
    "        te.loc[te.date == day, \"sales\"] = \\\n",
    "            alpha * blended_predictions(tst,[0.15,0.2,0.18,0.1,0.27,0.1])  # magic multiplier by kyakovlev\n",
    "        \n",
    "#         create_lag_features_for_test(tst1, day)  # faster  \n",
    "#         tst1 = tst1.loc[tst1.date == day, train_cols]\n",
    "#         te1.loc[te1.date == day, \"sales\"] = \\\n",
    "#             alpha * m_lgb1.predict(tst1)  # magic multiplier by kyakovlev\n",
    "\n",
    "    te_sub = te.loc[te.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "#     te_sub1 = te1.loc[te1.date >= fday, [\"id\", \"sales\"]].copy()\n",
    "\n",
    "    te_sub[\"F\"] = [f\"F{rank}\" for rank in te_sub.groupby(\"id\")[\n",
    "        \"id\"].cumcount()+1]\n",
    "#     te_sub1[\"F\"] = [f\"F{rank}\" for rank in te_sub1.groupby(\"id\")[\n",
    "#         \"id\"].cumcount()+1]\n",
    "    te_sub = te_sub.set_index([\"id\", \"F\"]).unstack()[\n",
    "        \"sales\"][cols].reset_index()\n",
    "#     te_sub1 = te_sub1.set_index([\"id\", \"F\"]).unstack()[\n",
    "#         \"sales\"][cols].reset_index()\n",
    "    \n",
    "    te_sub.fillna(0., inplace=True)\n",
    "#     te_sub1.fillna(0., inplace=True)\n",
    "    te_sub.sort_values(\"id\", inplace=True)\n",
    "#     te_sub1.sort_values(\"id\", inplace=True)\n",
    "    te_sub.reset_index(drop=True, inplace=True)\n",
    "#     te_sub1.reset_index(drop=True, inplace=True)\n",
    "    te_sub.to_csv(f\"submission_{icount}.csv\", index=False)\n",
    "#     te_sub1.to_csv(f\"submission1_{icount}.csv\", index=False)\n",
    "    if icount == 0:\n",
    "        sub = te_sub\n",
    "        sub[cols] *= weight\n",
    "#         sub1 = te_sub1\n",
    "#         sub1[cols] *= weight\n",
    "    else:\n",
    "        sub[cols] += te_sub[cols]*weight\n",
    "#         sub1[cols] += te_sub1[cols]*weight\n",
    "    print(icount, alpha, weight)\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>F</th>\n",
       "      <th>id</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "      <th>F25</th>\n",
       "      <th>F26</th>\n",
       "      <th>F27</th>\n",
       "      <th>F28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FOODS_1_001_CA_1_validation</td>\n",
       "      <td>1.058827</td>\n",
       "      <td>0.926531</td>\n",
       "      <td>0.903701</td>\n",
       "      <td>0.774120</td>\n",
       "      <td>1.223870</td>\n",
       "      <td>1.890662</td>\n",
       "      <td>1.460279</td>\n",
       "      <td>1.098264</td>\n",
       "      <td>0.931888</td>\n",
       "      <td>1.056411</td>\n",
       "      <td>1.000518</td>\n",
       "      <td>1.047267</td>\n",
       "      <td>1.397696</td>\n",
       "      <td>1.296467</td>\n",
       "      <td>1.033008</td>\n",
       "      <td>0.970131</td>\n",
       "      <td>0.974555</td>\n",
       "      <td>0.925467</td>\n",
       "      <td>0.925055</td>\n",
       "      <td>1.468578</td>\n",
       "      <td>1.450725</td>\n",
       "      <td>1.141369</td>\n",
       "      <td>0.981721</td>\n",
       "      <td>0.855966</td>\n",
       "      <td>0.859843</td>\n",
       "      <td>1.030539</td>\n",
       "      <td>1.561437</td>\n",
       "      <td>1.354006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FOODS_1_001_CA_2_validation</td>\n",
       "      <td>1.317097</td>\n",
       "      <td>1.426269</td>\n",
       "      <td>1.422646</td>\n",
       "      <td>1.494211</td>\n",
       "      <td>1.361276</td>\n",
       "      <td>2.023845</td>\n",
       "      <td>1.767464</td>\n",
       "      <td>1.301371</td>\n",
       "      <td>1.210966</td>\n",
       "      <td>1.180979</td>\n",
       "      <td>1.087307</td>\n",
       "      <td>1.273990</td>\n",
       "      <td>1.903118</td>\n",
       "      <td>1.575461</td>\n",
       "      <td>1.433890</td>\n",
       "      <td>1.331867</td>\n",
       "      <td>1.445444</td>\n",
       "      <td>1.280319</td>\n",
       "      <td>1.526670</td>\n",
       "      <td>1.923604</td>\n",
       "      <td>2.105449</td>\n",
       "      <td>1.578880</td>\n",
       "      <td>1.537052</td>\n",
       "      <td>1.357869</td>\n",
       "      <td>1.589528</td>\n",
       "      <td>1.588542</td>\n",
       "      <td>2.012241</td>\n",
       "      <td>1.759063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOODS_1_001_CA_3_validation</td>\n",
       "      <td>1.312026</td>\n",
       "      <td>1.074973</td>\n",
       "      <td>1.103476</td>\n",
       "      <td>1.038120</td>\n",
       "      <td>1.271298</td>\n",
       "      <td>1.476042</td>\n",
       "      <td>1.024638</td>\n",
       "      <td>1.063821</td>\n",
       "      <td>0.970325</td>\n",
       "      <td>1.123459</td>\n",
       "      <td>0.845632</td>\n",
       "      <td>0.945719</td>\n",
       "      <td>1.566098</td>\n",
       "      <td>1.398360</td>\n",
       "      <td>1.065367</td>\n",
       "      <td>1.277534</td>\n",
       "      <td>1.110474</td>\n",
       "      <td>1.137652</td>\n",
       "      <td>1.144523</td>\n",
       "      <td>1.220157</td>\n",
       "      <td>1.707964</td>\n",
       "      <td>1.258867</td>\n",
       "      <td>1.144596</td>\n",
       "      <td>1.058437</td>\n",
       "      <td>1.049645</td>\n",
       "      <td>1.208393</td>\n",
       "      <td>1.433991</td>\n",
       "      <td>1.243675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FOODS_1_001_CA_4_validation</td>\n",
       "      <td>0.639965</td>\n",
       "      <td>0.297954</td>\n",
       "      <td>0.268445</td>\n",
       "      <td>0.239696</td>\n",
       "      <td>0.384143</td>\n",
       "      <td>0.459579</td>\n",
       "      <td>0.820371</td>\n",
       "      <td>0.541576</td>\n",
       "      <td>0.678017</td>\n",
       "      <td>0.538475</td>\n",
       "      <td>0.522237</td>\n",
       "      <td>0.414339</td>\n",
       "      <td>0.442285</td>\n",
       "      <td>0.600868</td>\n",
       "      <td>0.493204</td>\n",
       "      <td>0.405809</td>\n",
       "      <td>0.499541</td>\n",
       "      <td>0.492930</td>\n",
       "      <td>0.463999</td>\n",
       "      <td>0.550847</td>\n",
       "      <td>0.623969</td>\n",
       "      <td>0.469221</td>\n",
       "      <td>0.482378</td>\n",
       "      <td>0.400869</td>\n",
       "      <td>0.438260</td>\n",
       "      <td>0.473852</td>\n",
       "      <td>0.574920</td>\n",
       "      <td>0.555241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FOODS_1_001_TX_1_validation</td>\n",
       "      <td>0.268965</td>\n",
       "      <td>0.236523</td>\n",
       "      <td>0.241944</td>\n",
       "      <td>0.192760</td>\n",
       "      <td>0.360487</td>\n",
       "      <td>0.254245</td>\n",
       "      <td>0.450536</td>\n",
       "      <td>0.457269</td>\n",
       "      <td>0.448953</td>\n",
       "      <td>0.428681</td>\n",
       "      <td>0.381721</td>\n",
       "      <td>0.414270</td>\n",
       "      <td>0.529724</td>\n",
       "      <td>0.497540</td>\n",
       "      <td>0.443132</td>\n",
       "      <td>0.492975</td>\n",
       "      <td>0.351639</td>\n",
       "      <td>0.331492</td>\n",
       "      <td>0.299704</td>\n",
       "      <td>0.343067</td>\n",
       "      <td>0.350458</td>\n",
       "      <td>0.450102</td>\n",
       "      <td>0.292367</td>\n",
       "      <td>0.356418</td>\n",
       "      <td>0.319314</td>\n",
       "      <td>0.599641</td>\n",
       "      <td>0.497141</td>\n",
       "      <td>0.312718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FOODS_1_001_TX_2_validation</td>\n",
       "      <td>0.485398</td>\n",
       "      <td>0.517172</td>\n",
       "      <td>0.549968</td>\n",
       "      <td>0.500509</td>\n",
       "      <td>0.407891</td>\n",
       "      <td>0.538648</td>\n",
       "      <td>0.453575</td>\n",
       "      <td>0.435443</td>\n",
       "      <td>0.467954</td>\n",
       "      <td>0.454960</td>\n",
       "      <td>0.447594</td>\n",
       "      <td>0.472915</td>\n",
       "      <td>0.529312</td>\n",
       "      <td>0.656911</td>\n",
       "      <td>0.461197</td>\n",
       "      <td>0.464991</td>\n",
       "      <td>0.469800</td>\n",
       "      <td>0.485435</td>\n",
       "      <td>0.487344</td>\n",
       "      <td>0.603270</td>\n",
       "      <td>0.715370</td>\n",
       "      <td>0.533080</td>\n",
       "      <td>0.458642</td>\n",
       "      <td>0.448767</td>\n",
       "      <td>0.442985</td>\n",
       "      <td>0.426542</td>\n",
       "      <td>0.534148</td>\n",
       "      <td>0.492605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FOODS_1_001_TX_3_validation</td>\n",
       "      <td>0.514938</td>\n",
       "      <td>0.658550</td>\n",
       "      <td>0.589034</td>\n",
       "      <td>0.528697</td>\n",
       "      <td>0.466291</td>\n",
       "      <td>0.527866</td>\n",
       "      <td>0.599805</td>\n",
       "      <td>0.768214</td>\n",
       "      <td>0.733689</td>\n",
       "      <td>0.665683</td>\n",
       "      <td>0.630758</td>\n",
       "      <td>0.548069</td>\n",
       "      <td>0.606030</td>\n",
       "      <td>0.735238</td>\n",
       "      <td>0.663283</td>\n",
       "      <td>0.846560</td>\n",
       "      <td>0.661995</td>\n",
       "      <td>0.671341</td>\n",
       "      <td>0.723298</td>\n",
       "      <td>0.634627</td>\n",
       "      <td>0.732829</td>\n",
       "      <td>0.592319</td>\n",
       "      <td>0.606623</td>\n",
       "      <td>0.527495</td>\n",
       "      <td>0.547235</td>\n",
       "      <td>0.544185</td>\n",
       "      <td>0.777353</td>\n",
       "      <td>0.725912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FOODS_1_001_WI_1_validation</td>\n",
       "      <td>0.358039</td>\n",
       "      <td>0.566395</td>\n",
       "      <td>0.436834</td>\n",
       "      <td>0.398408</td>\n",
       "      <td>0.413546</td>\n",
       "      <td>1.475371</td>\n",
       "      <td>0.866019</td>\n",
       "      <td>0.776447</td>\n",
       "      <td>0.723765</td>\n",
       "      <td>0.653270</td>\n",
       "      <td>0.868345</td>\n",
       "      <td>0.760128</td>\n",
       "      <td>0.719462</td>\n",
       "      <td>0.885766</td>\n",
       "      <td>0.874730</td>\n",
       "      <td>0.672322</td>\n",
       "      <td>0.661128</td>\n",
       "      <td>0.831927</td>\n",
       "      <td>0.709778</td>\n",
       "      <td>1.046373</td>\n",
       "      <td>0.930262</td>\n",
       "      <td>0.780305</td>\n",
       "      <td>0.866304</td>\n",
       "      <td>0.832210</td>\n",
       "      <td>0.833448</td>\n",
       "      <td>0.812112</td>\n",
       "      <td>1.079288</td>\n",
       "      <td>0.897837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FOODS_1_001_WI_2_validation</td>\n",
       "      <td>0.349611</td>\n",
       "      <td>0.514288</td>\n",
       "      <td>0.445519</td>\n",
       "      <td>0.394681</td>\n",
       "      <td>0.259565</td>\n",
       "      <td>0.492942</td>\n",
       "      <td>0.502034</td>\n",
       "      <td>0.443571</td>\n",
       "      <td>0.518466</td>\n",
       "      <td>0.481094</td>\n",
       "      <td>0.439055</td>\n",
       "      <td>0.470065</td>\n",
       "      <td>0.539077</td>\n",
       "      <td>0.515650</td>\n",
       "      <td>0.459750</td>\n",
       "      <td>0.508970</td>\n",
       "      <td>0.439432</td>\n",
       "      <td>0.440537</td>\n",
       "      <td>0.426487</td>\n",
       "      <td>0.611250</td>\n",
       "      <td>0.614085</td>\n",
       "      <td>0.445556</td>\n",
       "      <td>0.430920</td>\n",
       "      <td>0.436867</td>\n",
       "      <td>0.470603</td>\n",
       "      <td>0.450685</td>\n",
       "      <td>0.515704</td>\n",
       "      <td>0.454031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FOODS_1_001_WI_3_validation</td>\n",
       "      <td>0.273372</td>\n",
       "      <td>0.237525</td>\n",
       "      <td>0.378528</td>\n",
       "      <td>0.490745</td>\n",
       "      <td>0.459720</td>\n",
       "      <td>0.662068</td>\n",
       "      <td>0.419884</td>\n",
       "      <td>0.417412</td>\n",
       "      <td>0.594656</td>\n",
       "      <td>0.428212</td>\n",
       "      <td>0.520047</td>\n",
       "      <td>0.602147</td>\n",
       "      <td>0.486472</td>\n",
       "      <td>0.487083</td>\n",
       "      <td>0.527373</td>\n",
       "      <td>0.487278</td>\n",
       "      <td>0.427399</td>\n",
       "      <td>0.452472</td>\n",
       "      <td>0.472267</td>\n",
       "      <td>0.469996</td>\n",
       "      <td>0.487478</td>\n",
       "      <td>0.582859</td>\n",
       "      <td>0.469362</td>\n",
       "      <td>0.449893</td>\n",
       "      <td>0.493325</td>\n",
       "      <td>0.646811</td>\n",
       "      <td>0.703650</td>\n",
       "      <td>0.542971</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "F                           id        F1        F2        F3        F4  \\\n",
       "0  FOODS_1_001_CA_1_validation  1.058827  0.926531  0.903701  0.774120   \n",
       "1  FOODS_1_001_CA_2_validation  1.317097  1.426269  1.422646  1.494211   \n",
       "2  FOODS_1_001_CA_3_validation  1.312026  1.074973  1.103476  1.038120   \n",
       "3  FOODS_1_001_CA_4_validation  0.639965  0.297954  0.268445  0.239696   \n",
       "4  FOODS_1_001_TX_1_validation  0.268965  0.236523  0.241944  0.192760   \n",
       "5  FOODS_1_001_TX_2_validation  0.485398  0.517172  0.549968  0.500509   \n",
       "6  FOODS_1_001_TX_3_validation  0.514938  0.658550  0.589034  0.528697   \n",
       "7  FOODS_1_001_WI_1_validation  0.358039  0.566395  0.436834  0.398408   \n",
       "8  FOODS_1_001_WI_2_validation  0.349611  0.514288  0.445519  0.394681   \n",
       "9  FOODS_1_001_WI_3_validation  0.273372  0.237525  0.378528  0.490745   \n",
       "\n",
       "F        F5        F6        F7        F8        F9       F10       F11  \\\n",
       "0  1.223870  1.890662  1.460279  1.098264  0.931888  1.056411  1.000518   \n",
       "1  1.361276  2.023845  1.767464  1.301371  1.210966  1.180979  1.087307   \n",
       "2  1.271298  1.476042  1.024638  1.063821  0.970325  1.123459  0.845632   \n",
       "3  0.384143  0.459579  0.820371  0.541576  0.678017  0.538475  0.522237   \n",
       "4  0.360487  0.254245  0.450536  0.457269  0.448953  0.428681  0.381721   \n",
       "5  0.407891  0.538648  0.453575  0.435443  0.467954  0.454960  0.447594   \n",
       "6  0.466291  0.527866  0.599805  0.768214  0.733689  0.665683  0.630758   \n",
       "7  0.413546  1.475371  0.866019  0.776447  0.723765  0.653270  0.868345   \n",
       "8  0.259565  0.492942  0.502034  0.443571  0.518466  0.481094  0.439055   \n",
       "9  0.459720  0.662068  0.419884  0.417412  0.594656  0.428212  0.520047   \n",
       "\n",
       "F       F12       F13       F14       F15       F16       F17       F18  \\\n",
       "0  1.047267  1.397696  1.296467  1.033008  0.970131  0.974555  0.925467   \n",
       "1  1.273990  1.903118  1.575461  1.433890  1.331867  1.445444  1.280319   \n",
       "2  0.945719  1.566098  1.398360  1.065367  1.277534  1.110474  1.137652   \n",
       "3  0.414339  0.442285  0.600868  0.493204  0.405809  0.499541  0.492930   \n",
       "4  0.414270  0.529724  0.497540  0.443132  0.492975  0.351639  0.331492   \n",
       "5  0.472915  0.529312  0.656911  0.461197  0.464991  0.469800  0.485435   \n",
       "6  0.548069  0.606030  0.735238  0.663283  0.846560  0.661995  0.671341   \n",
       "7  0.760128  0.719462  0.885766  0.874730  0.672322  0.661128  0.831927   \n",
       "8  0.470065  0.539077  0.515650  0.459750  0.508970  0.439432  0.440537   \n",
       "9  0.602147  0.486472  0.487083  0.527373  0.487278  0.427399  0.452472   \n",
       "\n",
       "F       F19       F20       F21       F22       F23       F24       F25  \\\n",
       "0  0.925055  1.468578  1.450725  1.141369  0.981721  0.855966  0.859843   \n",
       "1  1.526670  1.923604  2.105449  1.578880  1.537052  1.357869  1.589528   \n",
       "2  1.144523  1.220157  1.707964  1.258867  1.144596  1.058437  1.049645   \n",
       "3  0.463999  0.550847  0.623969  0.469221  0.482378  0.400869  0.438260   \n",
       "4  0.299704  0.343067  0.350458  0.450102  0.292367  0.356418  0.319314   \n",
       "5  0.487344  0.603270  0.715370  0.533080  0.458642  0.448767  0.442985   \n",
       "6  0.723298  0.634627  0.732829  0.592319  0.606623  0.527495  0.547235   \n",
       "7  0.709778  1.046373  0.930262  0.780305  0.866304  0.832210  0.833448   \n",
       "8  0.426487  0.611250  0.614085  0.445556  0.430920  0.436867  0.470603   \n",
       "9  0.472267  0.469996  0.487478  0.582859  0.469362  0.449893  0.493325   \n",
       "\n",
       "F       F26       F27       F28  \n",
       "0  1.030539  1.561437  1.354006  \n",
       "1  1.588542  2.012241  1.759063  \n",
       "2  1.208393  1.433991  1.243675  \n",
       "3  0.473852  0.574920  0.555241  \n",
       "4  0.599641  0.497141  0.312718  \n",
       "5  0.426542  0.534148  0.492605  \n",
       "6  0.544185  0.777353  0.725912  \n",
       "7  0.812112  1.079288  0.897837  \n",
       "8  0.450685  0.515704  0.454031  \n",
       "9  0.646811  0.703650  0.542971  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 30490)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.id.nunique(), sub[\"id\"].str.contains(\"validation$\").sum()\n",
    "# sub1.id.nunique(), sub1[\"id\"].str.contains(\"validation$\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 29)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.shape\n",
    "# sub1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2 = sub.copy()\n",
    "sub2[\"id\"] = sub2[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "sub = pd.concat([sub, sub2], axis=0, sort=False)\n",
    "sub.to_csv(\"submissionp.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub3 = sub1.copy()\n",
    "# sub3[\"id\"] = sub3[\"id\"].str.replace(\"validation$\", \"evaluation\")\n",
    "# sub1 = pd.concat([sub1, sub3], axis=0, sort=False)\n",
    "# sub.to_csv(\"submissiont.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisson = sub.sort_values(by = 'id').reset_index(drop = True)\n",
    "# tweedie = sub1.sort_values(by = 'id').reset_index(drop = True)\n",
    "# sub5 = poisson.copy()\n",
    "\n",
    "# for i in sub5.columns :\n",
    "#     if i != 'id' :\n",
    "#         sub5[i] = 0.5*poisson[i] + 0.5*tweedie[i]\n",
    "        \n",
    "# sub5.to_csv('submissionavg.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
