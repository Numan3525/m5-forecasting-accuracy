{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1941         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Main Data\n"
     ]
    }
   ],
   "source": [
    "########################### Load Data\n",
    "#################################################################################\n",
    "print('Load Main Data')\n",
    "\n",
    "# We will need only train dataset\n",
    "# to show lags concept\n",
    "train_df = pd.read_csv('../input/walmartadd/sales.csv')\n",
    "\n",
    "walmartadd = pd.read_csv('../input/m5-forecasting-uncertainty/sales_train_evaluation.csv')\n",
    "train_df = train_df.drop([x for x in range(len(walmartadd),len(train_df))], axis=0)\n",
    "del walmartadd\n",
    "drop_me = [f'd_{x}' for x in range(1,600)]\n",
    "train_df = train_df.drop(drop_me, axis=1)\n",
    "# To make all calculations faster\n",
    "# we will limit dataset by 'CA' state\n",
    "train_df = train_df[train_df['state_id']=='CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (12196, 1350)\n"
     ]
    }
   ],
   "source": [
    "########################### Data Representation\n",
    "#################################################################################\n",
    "\n",
    "# Let's check our shape\n",
    "print('Shape', train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d_600</th>\n",
       "      <th>d_601</th>\n",
       "      <th>d_602</th>\n",
       "      <th>d_603</th>\n",
       "      <th>...</th>\n",
       "      <th>d_1934</th>\n",
       "      <th>d_1935</th>\n",
       "      <th>d_1936</th>\n",
       "      <th>d_1937</th>\n",
       "      <th>d_1938</th>\n",
       "      <th>d_1939</th>\n",
       "      <th>d_1940</th>\n",
       "      <th>d_1941</th>\n",
       "      <th>start</th>\n",
       "      <th>scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOBBIES_1_001_CA_1</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>901</td>\n",
       "      <td>0.773603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HOBBIES_1_002_CA_1</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>0.422049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HOBBIES_1_003_CA_1</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1105</td>\n",
       "      <td>0.511990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HOBBIES_1_004_CA_1</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>36</td>\n",
       "      <td>1.778245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HOBBIES_1_005_CA_1</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>1.102354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HOBBIES_1_006_CA_1</td>\n",
       "      <td>HOBBIES_1_006</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "      <td>1.479470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HOBBIES_1_007_CA_1</td>\n",
       "      <td>HOBBIES_1_007</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>530</td>\n",
       "      <td>0.479773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HOBBIES_1_008_CA_1</td>\n",
       "      <td>HOBBIES_1_008</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>7.521403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HOBBIES_1_009_CA_1</td>\n",
       "      <td>HOBBIES_1_009</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.620423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HOBBIES_1_010_CA_1</td>\n",
       "      <td>HOBBIES_1_010</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.851316</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 1350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id        item_id    dept_id   cat_id store_id state_id  \\\n",
       "0  HOBBIES_1_001_CA_1  HOBBIES_1_001  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "1  HOBBIES_1_002_CA_1  HOBBIES_1_002  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "2  HOBBIES_1_003_CA_1  HOBBIES_1_003  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "3  HOBBIES_1_004_CA_1  HOBBIES_1_004  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "4  HOBBIES_1_005_CA_1  HOBBIES_1_005  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "5  HOBBIES_1_006_CA_1  HOBBIES_1_006  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "6  HOBBIES_1_007_CA_1  HOBBIES_1_007  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "7  HOBBIES_1_008_CA_1  HOBBIES_1_008  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "8  HOBBIES_1_009_CA_1  HOBBIES_1_009  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "9  HOBBIES_1_010_CA_1  HOBBIES_1_010  HOBBIES_1  HOBBIES     CA_1       CA   \n",
       "\n",
       "   d_600  d_601  d_602  d_603  ...  d_1934  d_1935  d_1936  d_1937  d_1938  \\\n",
       "0      0      0      0      0  ...       0       0       0       0       3   \n",
       "1      0      0      1      1  ...       2       1       1       0       0   \n",
       "2      0      0      0      0  ...       2       0       0       0       2   \n",
       "3      0      1      1      3  ...       0       4       0       1       3   \n",
       "4      0      2      0      4  ...       0       2       1       0       0   \n",
       "5      0      2      0      5  ...       0       0       1       0       0   \n",
       "6      0      1      0      0  ...       0       0       0       1       0   \n",
       "7      0      0      0      0  ...       6       0      15       5       4   \n",
       "8      0      1      3      0  ...       0       0       0       0       0   \n",
       "9      0      0      0      0  ...       1       0       2       1       1   \n",
       "\n",
       "   d_1939  d_1940  d_1941  start     scale  \n",
       "0       3       0       1    901  0.773603  \n",
       "1       0       0       0    143  0.422049  \n",
       "2       3       0       1   1105  0.511990  \n",
       "3       0       2       6     36  1.778245  \n",
       "4       2       1       0    112  1.102354  \n",
       "5       5       2       0    429  1.479470  \n",
       "6       1       1       0    530  0.479773  \n",
       "7       1      40      32      0  7.521403  \n",
       "8       0       1       0      0  1.620423  \n",
       "9       0       0       1      2  0.851316  \n",
       "\n",
       "[10 rows x 1350 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Horizontal representation\n",
    "\n",
    "# If we feed directly this data to model\n",
    "# our label will be values in column 'd_1913'\n",
    "# all other columns will be our \"features\"\n",
    "\n",
    "# In lag terminology all d_1->d_1912 columns\n",
    "# are our lag features \n",
    "# (target values in previous time period)\n",
    "\n",
    "# Good thing that we have a lot of features here\n",
    "# Bad thing is that we have just 12196 \"train rows\"\n",
    "# Note: here and after all numbers are limited to 'CA' state\n",
    "train_df.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, item_id, dept_id, cat_id, store_id, state_id, d, sales]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Vertical representation\n",
    "\n",
    "# In other hand we can think of d_ columns\n",
    "# as additional labels and can significantly \n",
    "# scale up our training set to 23330948 rows\n",
    "\n",
    "# Good thing that our model will have \n",
    "# greater input for training\n",
    "# Bad thing that we are losing lags that we had\n",
    "# in horizontal representation and\n",
    "# also new data set consumes much more memory\n",
    "\n",
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id','scale']\n",
    "train_df = pd.melt(train_df, \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "train_df[TARGET] = train_df[TARGET] / train_df['scale']\n",
    "train_df = train_df.drop('scale',axis=1)\n",
    "train_df[train_df['id']=='HOBBIES_1_001_CA_1_evaluation'].iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'art'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-26660661cc80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Some minification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0micols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'item_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'dept_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cat_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'store_id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'state_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0micols\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5880\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5881\u001b[0m             new_data = self._data.astype(\n\u001b[0;32m-> 5882\u001b[0;31m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5883\u001b[0m             )\n\u001b[1;32m   5884\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m                     \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m                     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0;31m# TODO(extension)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'art'"
     ]
    }
   ],
   "source": [
    "## Some minification\n",
    "train_df['d'] = train_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n",
    "\n",
    "icols = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "for col in icols:\n",
    "    train_df[col] = train_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shifting: 1\n",
      "Shifting: 2\n",
      "Shifting: 3\n",
      "Shifting: 4\n",
      "Shifting: 5\n",
      "Shifting: 6\n",
      "Shifting: 7\n",
      "1.90 min: Time for loops\n",
      "1.82 min: Time for bulk shift\n"
     ]
    }
   ],
   "source": [
    "########################### Lags creation\n",
    "#################################################################################\n",
    "\n",
    "# We have several \"code\" solutions here\n",
    "# As our dataset is allready sorted by d values\n",
    "# we can simply shift() values\n",
    "# also we have to keep in mind that \n",
    "# we need to aggregate values on 'id' level\n",
    "\n",
    "# group and shift in loop\n",
    "temp_df = train_df[['id','d',TARGET]]\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(1,8):\n",
    "    print('Shifting:', i)\n",
    "    temp_df['lag_'+str(i)] = temp_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(i))\n",
    "    \n",
    "print('%0.2f min: Time for loops' % ((time.time() - start_time) / 60))\n",
    "\n",
    "\n",
    "# Or same in \"compact\" manner\n",
    "LAG_DAYS = [col for col in range(1,8)]\n",
    "temp_df = train_df[['id','d',TARGET]]\n",
    "\n",
    "start_time = time.time()\n",
    "temp_df = temp_df.assign(**{\n",
    "        '{}_lag_{}'.format(col, l): temp_df.groupby(['id'])[col].transform(lambda x: x.shift(l))\n",
    "        for l in LAG_DAYS\n",
    "        for col in [TARGET]\n",
    "    })\n",
    "\n",
    "print('%0.2f min: Time for bulk shift' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>sales_lag_1</th>\n",
       "      <th>sales_lag_2</th>\n",
       "      <th>sales_lag_3</th>\n",
       "      <th>sales_lag_4</th>\n",
       "      <th>sales_lag_5</th>\n",
       "      <th>sales_lag_6</th>\n",
       "      <th>sales_lag_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, d, sales, sales_lag_1, sales_lag_2, sales_lag_3, sales_lag_4, sales_lag_5, sales_lag_6, sales_lag_7]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result\n",
    "temp_df[temp_df['id']=='HOBBIES_1_001_CA_1_evaluation'].iloc[:10]\n",
    "\n",
    "# You can notice many NaNs values - it's normal\n",
    "# because there is no data for day 0,-1,-2\n",
    "# (out of dataset time periods)\n",
    "\n",
    "# Same works for test set\n",
    "# be careful to make lag features:\n",
    "# for day 1920 there is no data about day 1919 (until 1913)\n",
    "# So if you want to predict day 1915 your \n",
    "# lag features have to start from 2 \n",
    "# (1915(predicting day) - 1913(last day with label in dataset))\n",
    "# and so on.\n",
    "\n",
    "# There are few options to work \n",
    "# with NaNs in train set\n",
    "## 1. drop it train_df[train_df['d']>MAX_LAG_DAY] \n",
    "## 1.1 in our case we already dropped some lines by release date\n",
    "##     so you have find d.min() for each id\n",
    "##     and drop train_df[train_df['d']>(train_df['d_min']+MAX_LAG_DAY)] \n",
    "## 2. If you want to keep it you can \n",
    "##    fill with '-1' to be able to convert to int\n",
    "## 3. Leave as it is\n",
    "## 4. Fill with mean -> not recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling period: 14\n",
      "Rolling period: 30\n",
      "Rolling period: 60\n",
      "2.36 min: Time for loop\n"
     ]
    }
   ],
   "source": [
    "########################### Rolling lags\n",
    "#################################################################################\n",
    "\n",
    "# We restored some day sales values from horizontal representation\n",
    "# as lag features but just few of them (last 7 days or less)\n",
    "# because of memory limits we can't have many lag features\n",
    "# How we can get additional information from other days?\n",
    "\n",
    "## Rolling aggragations\n",
    "\n",
    "temp_df = train_df[['id','d','sales']]\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in [14,30,60]:\n",
    "    print('Rolling period:', i)\n",
    "    temp_df['rolling_mean_'+str(i)] = temp_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(1).rolling(i).mean())\n",
    "    temp_df['rolling_std_'+str(i)]  = temp_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(1).rolling(i).std())\n",
    "\n",
    "# lambda x: x.shift(1)\n",
    "# 1 day shift will serve only to predict day 1914\n",
    "# for other days you have to shift PREDICT_DAY-1913\n",
    "\n",
    "# Such aggregations will help us to restore\n",
    "# at least part of the information for our model\n",
    "# and out of 14+30+60->104 columns we can have just 6\n",
    "# with valuable information (hope it is sufficient)\n",
    "# you can also aggregate by max/skew/median etc \n",
    "# also you can try other rolling periods 180,365 etc\n",
    "print('%0.2f min: Time for loop' % ((time.time() - start_time) / 60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>rolling_mean_14</th>\n",
       "      <th>rolling_std_14</th>\n",
       "      <th>rolling_mean_30</th>\n",
       "      <th>rolling_std_30</th>\n",
       "      <th>rolling_mean_60</th>\n",
       "      <th>rolling_std_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, d, sales, rolling_mean_14, rolling_std_14, rolling_mean_30, rolling_std_30, rolling_mean_60, rolling_std_60]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The result\n",
    "temp_df[temp_df['id']=='HOBBIES_1_002_CA_1_evaluation'].iloc[:20]\n",
    "\n",
    "# Same for NaNs values - it's normal\n",
    "# because there is no data for \n",
    "# 0*(rolling_period),-1*(rolling_period),-2*(rolling_period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original rolling df:   1.1GiB\n",
      "   Values rolling df: 749.8MiB\n"
     ]
    }
   ],
   "source": [
    "########################### Memory ussage\n",
    "#################################################################################\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original rolling df',sizeof_fmt(temp_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# can we minify it?\n",
    "# 1. if our dataset are aligned by index \n",
    "#    you don't need 'id' 'd' 'sales' columns\n",
    "temp_df = temp_df.iloc[:,3:]\n",
    "print(\"{:>20}: {:>8}\".format('Values rolling df',sizeof_fmt(temp_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# can we make it even smaller?\n",
    "# carefully change dtype and/or\n",
    "# use sparce matrix to minify 0s\n",
    "# Also note that lgbm accepts matrixes as input\n",
    "# that is good for memory reducion \n",
    "from scipy import sparse \n",
    "temp_matrix = sparse.csr_matrix(temp_df)\n",
    "\n",
    "# restore to df\n",
    "temp_matrix_restored = pd.DataFrame(temp_matrix.todense())\n",
    "restored_cols = ['roll_' + str(i) for i in list(temp_matrix_restored)]\n",
    "temp_matrix_restored.columns = restored_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Remove old objects\n",
    "#################################################################################\n",
    "del temp_df, train_df, temp_matrix, temp_matrix_restored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create lags\n",
      "7.82 min: Lags\n",
      "Create rolling aggs\n",
      "Rolling period: 7\n",
      "Rolling period: 14\n",
      "Rolling period: 30\n",
      "Rolling period: 60\n",
      "Rolling period: 180\n",
      "Shifting period: 1\n",
      "Shifting period: 7\n",
      "Shifting period: 14\n",
      "18.86 min: Lags\n"
     ]
    }
   ],
   "source": [
    "########################### Apply on grid_df\n",
    "#################################################################################\n",
    "# lets read grid from \n",
    "# https://www.kaggle.com/kyakovlev/m5-simple-fe\n",
    "# to be sure that our grids are aligned by index\n",
    "grid_df = pd.read_pickle('../input/m5-uncertainty-simple-fe/grid_part_1.pkl')\n",
    "\n",
    "# We need only 'id','d','sales'\n",
    "# to make lags and rollings\n",
    "grid_df = grid_df[['id','d','sales']]\n",
    "SHIFT_DAY = 28\n",
    "\n",
    "# Lags\n",
    "# with 28 day shift\n",
    "start_time = time.time()\n",
    "print('Create lags')\n",
    "\n",
    "LAG_DAYS = [col for col in range(SHIFT_DAY,SHIFT_DAY+15)]\n",
    "grid_df = grid_df.assign(**{\n",
    "        '{}_lag_{}'.format(col, l): grid_df.groupby(['id'])[col].transform(lambda x: x.shift(l))\n",
    "        for l in LAG_DAYS\n",
    "        for col in [TARGET]\n",
    "    })\n",
    "\n",
    "# Minify lag columns\n",
    "for col in list(grid_df):\n",
    "    if 'lag' in col:\n",
    "        grid_df[col] = grid_df[col].astype(np.float16)\n",
    "\n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))\n",
    "\n",
    "# Rollings\n",
    "# with 28 day shift\n",
    "start_time = time.time()\n",
    "print('Create rolling aggs')\n",
    "\n",
    "for i in [7,14,30,60,180]:\n",
    "    print('Rolling period:', i)\n",
    "    grid_df['rolling_mean_'+str(i)] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).mean()).astype(np.float16)\n",
    "    grid_df['rolling_std_'+str(i)]  = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(SHIFT_DAY).rolling(i).std()).astype(np.float16)\n",
    "\n",
    "# Rollings\n",
    "# with sliding shift\n",
    "for d_shift in [1,7,14]: \n",
    "    print('Shifting period:', d_shift)\n",
    "    for d_window in [7,14,30,60]:\n",
    "        col_name = 'rolling_mean_tmp_'+str(d_shift)+'_'+str(d_window)\n",
    "        grid_df[col_name] = grid_df.groupby(['id'])[TARGET].transform(lambda x: x.shift(d_shift).rolling(d_window).mean()).astype(np.float16)\n",
    "    \n",
    "    \n",
    "print('%0.2f min: Lags' % ((time.time() - start_time) / 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save lags and rollings\n"
     ]
    }
   ],
   "source": [
    "########################### Export\n",
    "#################################################################################\n",
    "print('Save lags and rollings')\n",
    "grid_df.to_pickle('lags_df_'+str(SHIFT_DAY)+'.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37629667 entries, 0 to 37629666\n",
      "Data columns (total 40 columns):\n",
      "id                        category\n",
      "d                         int16\n",
      "sales                     float64\n",
      "sales_lag_28              float16\n",
      "sales_lag_29              float16\n",
      "sales_lag_30              float16\n",
      "sales_lag_31              float16\n",
      "sales_lag_32              float16\n",
      "sales_lag_33              float16\n",
      "sales_lag_34              float16\n",
      "sales_lag_35              float16\n",
      "sales_lag_36              float16\n",
      "sales_lag_37              float16\n",
      "sales_lag_38              float16\n",
      "sales_lag_39              float16\n",
      "sales_lag_40              float16\n",
      "sales_lag_41              float16\n",
      "sales_lag_42              float16\n",
      "rolling_mean_7            float16\n",
      "rolling_std_7             float16\n",
      "rolling_mean_14           float16\n",
      "rolling_std_14            float16\n",
      "rolling_mean_30           float16\n",
      "rolling_std_30            float16\n",
      "rolling_mean_60           float16\n",
      "rolling_std_60            float16\n",
      "rolling_mean_180          float16\n",
      "rolling_std_180           float16\n",
      "rolling_mean_tmp_1_7      float16\n",
      "rolling_mean_tmp_1_14     float16\n",
      "rolling_mean_tmp_1_30     float16\n",
      "rolling_mean_tmp_1_60     float16\n",
      "rolling_mean_tmp_7_7      float16\n",
      "rolling_mean_tmp_7_14     float16\n",
      "rolling_mean_tmp_7_30     float16\n",
      "rolling_mean_tmp_7_60     float16\n",
      "rolling_mean_tmp_14_7     float16\n",
      "rolling_mean_tmp_14_14    float16\n",
      "rolling_mean_tmp_14_30    float16\n",
      "rolling_mean_tmp_14_60    float16\n",
      "dtypes: category(1), float16(37), float64(1), int16(1)\n",
      "memory usage: 3.0 GB\n"
     ]
    }
   ],
   "source": [
    "########################### Final list of new features\n",
    "#################################################################################\n",
    "grid_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
